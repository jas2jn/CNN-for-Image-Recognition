{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Net for Image Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /opt/conda/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras) (1.13.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras) (1.3.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras) (5.1.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras) (1.17.4)\n"
     ]
    }
   ],
   "source": [
    " !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_png { display: table-cell; text-align: center; vertical-align: middle; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.MathJax {font-size: 100%;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IPython display functions\n",
    "import IPython\n",
    "from IPython.display import display, HTML, SVG, Image\n",
    "\n",
    "# General Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-paper')\n",
    "plt.rcParams['figure.figsize'] = [10, 6] ## plot size\n",
    "plt.rcParams['axes.linewidth'] = 2.0 #set the value globally\n",
    "\n",
    "## notebook style and settings\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_png { display: table-cell; text-align: center; vertical-align: middle; } </style>\"))\n",
    "display(HTML(\"<style>.MathJax {font-size: 100%;}</style>\"))\n",
    "\n",
    "# For changing background color\n",
    "def set_background(color):\n",
    "    script = ( \"var cell = this.closest('.code_cell');\" \"var editor = cell.querySelector('.input_area');\" \"editor.style.background='{}';\" \"this.parentNode.removeChild(this)\" ).format(color)\n",
    "    display(HTML('<img src onerror=\"{}\">'.format(script)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import walk\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# Keras library for deep learning\n",
    "# https://keras.io/\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import mnist # MNIST Data set\n",
    "from keras.models import Sequential # Model building\n",
    "from keras.layers import * # Model layers\n",
    "from keras.preprocessing.image import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Confusion Matrix\n",
    "Confusion matrices are an important toolkit in every data scientist's box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayConfusionMatrix(confusionMatrix, precisionNegative, precisionPositive, recallNegative, recallPositive, title):\n",
    "    # Set font size for the plots\n",
    "    PLOT_FONT_SIZE = 14\n",
    "    \n",
    "    # Set plot size\n",
    "    plt.rcParams['figure.figsize'] = [5, 5]\n",
    "    \n",
    "    # Transpose of confusion matrix to align the plot with the actual precision recall values\n",
    "    confusionMatrix = np.transpose(confusionMatrix)\n",
    "    \n",
    "    # Plotting the confusion matrix\n",
    "    plt.imshow(confusionMatrix, interpolation='nearest',cmap=plt.cm.Blues, vmin=0, vmax=100)\n",
    "    \n",
    "    \n",
    "    # Setting plot properties\n",
    "    xticks = np.array([-0.5, 0, 1,1.5])\n",
    "    plt.gca().set_xticks(xticks)\n",
    "    plt.gca().set_yticks(xticks)\n",
    "    plt.gca().set_xticklabels([\"\", \"Healthy\\nRecall=\" + str(recallNegative) , \"Pneumonia\\nRecall=\" + str(recallPositive), \"\"], fontsize=PLOT_FONT_SIZE)\n",
    "    plt.gca().set_yticklabels([\"\", \"Healthy\\nPrecision=\" + str(precisionNegative) , \"Pneumonia\\nPrecision=\" + str(precisionPositive), \"\"], fontsize=PLOT_FONT_SIZE)\n",
    "    plt.ylabel(\"Predicted Class\", fontsize=PLOT_FONT_SIZE)\n",
    "    plt.xlabel(\"Actual Class\", fontsize=PLOT_FONT_SIZE)\n",
    "    plt.title(title, fontsize=PLOT_FONT_SIZE)\n",
    "        \n",
    "    # Add text in heatmap boxes\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            text = plt.text(j, i, confusionMatrix[i][j], ha=\"center\", va=\"center\", color=\"white\", size=15) ### size here is the size of text inside a single box in the heatmap\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Metrics Calculation\n",
    "A function that will calculate all the metrics needed in order to analyze the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMetricsAndPrint(predictions, predictionsProbabilities, actualLabels):\n",
    "    # Convert label format from [0,1](label 1) and [1,0](label 0) into single integers: 1 and 0.\n",
    "    actualLabels = [item[1] for item in actualLabels]\n",
    "    \n",
    "    # Get probabilities for the class with label 1. That is all that is need to compute AUCs. Don't need probabilities for class 0.\n",
    "    predictionsProbabilities = [item[1] for item in predictionsProbabilities]\n",
    "    \n",
    "    # Calculate metrics using scikit-learn functions. The round function is used to round the numbers up to 2 decimal points.\n",
    "    accuracy = round(accuracy_score(actualLabels, predictions) * 100, 2)\n",
    "    precisionNegative = round(precision_score(actualLabels, predictions, average = None)[0] * 100, 2)\n",
    "    precisionPositive = round(precision_score(actualLabels, predictions, average = None)[1] * 100, 2)\n",
    "    recallNegative = round(recall_score(actualLabels, predictions, average = None)[0] * 100, 2)\n",
    "    recallPositive = round(recall_score(actualLabels, predictions, average = None)[1] * 100, 2)\n",
    "    auc = round(roc_auc_score(actualLabels, predictionsProbabilities) * 100, 2)\n",
    "    confusionMatrix = confusion_matrix(actualLabels, predictions)\n",
    "    \n",
    "    # Print metrics. .%2f prints a number upto 2 decimal points only.\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"Accuracy: %.2f\\nPrecisionNegative: %.2f\\nPrecisionPositive: %.2f\\nRecallNegative: %.2f\\nRecallPositive: %.2f\\nAUC Score: %.2f\" % \n",
    "          (accuracy, precisionNegative, precisionPositive, recallNegative, recallPositive, auc))\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    \n",
    "    print(\"+ Printing confusion matrix...\\n\")\n",
    "    # Display confusion matrix\n",
    "    displayConfusionMatrix(confusionMatrix, precisionNegative, precisionPositive, recallNegative, recallPositive, \"Confusion Matrix\")\n",
    "    \n",
    "    print(\"+ Printing ROC curve...\\n\")\n",
    "    # ROC Curve\n",
    "    plt.rcParams['figure.figsize'] = [16, 8]\n",
    "    FONT_SIZE = 16\n",
    "    falsePositiveRateDt, truePositiveRateDt, _ = roc_curve(actualLabels, predictionsProbabilities)\n",
    "    plt.plot(falsePositiveRateDt, truePositiveRateDt, linewidth = 5, color='black')\n",
    "    plt.xticks(fontsize=FONT_SIZE)\n",
    "    plt.yticks(fontsize=FONT_SIZE)\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=FONT_SIZE)\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=FONT_SIZE)\n",
    "    plt.show()\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKagglePredictions(model, kaggleData, filename):\n",
    "    print(\"+ Writing kaggle test results in : results/%s...\" % filename)\n",
    "    predictions = model.predict(kaggleData)\n",
    "    predictionProbs = [item[1] for item in predictions]\n",
    "        \n",
    "    # Store predictions for kaggle\n",
    "    outputFile = open(\"results/\" + str(filename), \"w\")\n",
    "    outputFile.write(\"Id,Prediction\\n\")\n",
    "    for i in range(0, len(predictionProbs)):\n",
    "        outputFile.write(str(i + 1) + \",\" + str(predictionProbs[i]) + \"\\n\")\n",
    "    \n",
    "    outputFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Top n% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateClasswiseTopNAccuracy(actualLabels, predictionsProbs, TOP_N):\n",
    "    \"\"\"\n",
    "    TOP_N is the top n% predictions to use for each class\n",
    "    \"\"\"\n",
    "\n",
    "    discreteActualLabels = [1 if item[1] > item[0] else 0 for item in actualLabels]\n",
    "    discretePredictions = [1 if item[1] > item[0] else 0 for item in predictionsProbs]\n",
    "    predictionProbsTopNHealthy, predictionProbsTopNPneumonia = [item[0] for item in predictionsProbs], [item[1] for item in predictionsProbs]\n",
    "    predictionProbsTopNHealthy = list(reversed(sorted(predictionProbsTopNHealthy)))[:int(len(predictionProbsTopNHealthy) * TOP_N / 100)][-1]\n",
    "    predictionProbsTopNPneumonia = list(reversed(sorted(predictionProbsTopNPneumonia)))[:int(len(predictionProbsTopNPneumonia) * TOP_N / 100)][-1]\n",
    "\n",
    "    # Calculate accuracy for both classes\n",
    "    accuracyHealthy = []\n",
    "    accuracyPneumonia = []\n",
    "    for i in range(0, len(discretePredictions)):\n",
    "        if discretePredictions[i] == 1:\n",
    "            # Pneumonia\n",
    "            if predictionsProbs[i][1] > predictionProbsTopNPneumonia:\n",
    "                accuracyPneumonia.append(int(discreteActualLabels[i]) == 1)\n",
    "        else:\n",
    "            # Healthy\n",
    "            if predictionsProbs[i][0] > predictionProbsTopNHealthy:\n",
    "                accuracyHealthy.append(int(discreteActualLabels[i]) == 0)\n",
    "\n",
    "    accuracyHealthy = round((accuracyHealthy.count(True) * 100) / len(accuracyHealthy), 2)\n",
    "    accuracyPneumonia = round((accuracyPneumonia.count(True) * 100) / len(accuracyPneumonia), 2)\n",
    "    return accuracyHealthy, accuracyPneumonia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Loading\n",
    "## 2.1 Loading File Paths\n",
    "Loading file paths from normal and pneumonia folders in the train directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal X-ray images: 1436\n",
      "Pneumonia X-ray images: 1436\n"
     ]
    }
   ],
   "source": [
    "# Load normal images\n",
    "normalImagesPath = \"data/train/normal\"\n",
    "normalImageFiles = []\n",
    "for(_,_,files) in walk(normalImagesPath):\n",
    "    normalImageFiles.extend(files)\n",
    "\n",
    "\n",
    "# Load pneumonia images\n",
    "pneumoniaImagesPath = \"data/train/pneumonia\"\n",
    "pneumoniaImageFiles = []\n",
    "for(_,_,files) in walk(pneumoniaImagesPath):\n",
    "    pneumoniaImageFiles.extend(files)\n",
    "    \n",
    "random.shuffle(pneumoniaImageFiles)\n",
    "pneumoniaImageFiles = pneumoniaImageFiles[:len(normalImageFiles)]\n",
    "print(\"Normal X-ray images: %d\\nPneumonia X-ray images: %d\" % (len(normalImageFiles), len(pneumoniaImageFiles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Loading Image Data\n",
    "### 2.2.1 Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: (2872, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "imagesData = []\n",
    "imagesLabels = []\n",
    "\n",
    "for file in normalImageFiles:\n",
    "    fullPath = normalImagesPath + \"/\" + file\n",
    "    if os.path.exists(fullPath) == False:\n",
    "            continue\n",
    "    imageData = load_img(normalImagesPath + \"/\" + file, color_mode = \"grayscale\") # load_img function comes from keras library using \"from keras.preprocessing.image import *\"\n",
    "    imageArray = img_to_array(imageData) / 255.0\n",
    "    \n",
    "    imagesData.append(imageArray)\n",
    "    imagesLabels.append(0)\n",
    "    \n",
    "\n",
    "for file in pneumoniaImageFiles:\n",
    "    fullPath = pneumoniaImagesPath + \"/\" + file\n",
    "    if os.path.exists(fullPath) == False:\n",
    "            continue\n",
    "            \n",
    "    imageData = load_img(pneumoniaImagesPath + \"/\" + file, color_mode = \"grayscale\") # load_img function comes from keras library using \"from keras.preprocessing.image import *\"\n",
    "    imageArray = img_to_array(imageData) / 255.0\n",
    "    \n",
    "    imagesData.append(imageArray)\n",
    "    imagesLabels.append(1)\n",
    "\n",
    "imagesData = np.array(imagesData)\n",
    "imagesLabels = keras.utils.to_categorical(imagesLabels)\n",
    "print(\"Input data shape: %s\" % (imagesData.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Kaggle Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test images: 200\n"
     ]
    }
   ],
   "source": [
    "testImagesPath = \"data/test/\"\n",
    "testImageFiles = []\n",
    "for(_,_,files) in walk(testImagesPath):\n",
    "    testImageFiles.extend(files)\n",
    "testImageFiles = list(sorted(testImageFiles))\n",
    "    \n",
    "kaggleTestImages = []\n",
    "for file in testImageFiles:\n",
    "    fullPath = testImagesPath + \"/\" + file\n",
    "    if os.path.exists(fullPath) == False:\n",
    "        continue\n",
    "    imageData = load_img(testImagesPath + \"/\" + file, color_mode = \"grayscale\") # load_img function comes from keras library when we do \"from keras.preprocessing.image import *\"\n",
    "    imageArray = img_to_array(imageData) / 255.0\n",
    "    \n",
    "    kaggleTestImages.append(imageArray)\n",
    "    \n",
    "kaggleTestImages = np.array(kaggleTestImages)\n",
    "print(\"Number of test images: %d\" % len(kaggleTestImages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Data Splitting into Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestSplit(data, labels):\n",
    "    \"\"\"\n",
    "    80-20 train-test data split\n",
    "    \"\"\"\n",
    "    trainData, trainLabels, testData, testLabels = [], [], [], []\n",
    "    for i in range(0, len(data)):\n",
    "        if i % 5 == 0:\n",
    "            testData.append(data[i])\n",
    "            testLabels.append(labels[i])\n",
    "        else:\n",
    "            trainData.append(data[i])\n",
    "            trainLabels.append(labels[i])\n",
    "            \n",
    "    return np.array(trainData), np.array(testData), np.array(trainLabels), np.array(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this context, since this was meant to be tested on a private kaggle competition, the test data here would actually mean validation data. Will use results on this validation(test) data to see how the model would perform on the actual test data.\n",
    "# Split data into 80% training and 20% testing\n",
    "trainData, testData, trainLabels, testLabels = trainTestSplit(imagesData, imagesLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deep Learning Models\n",
    "I will use keras to create deep learning models. For more details, please visit: https://keras.io/layers/convolutional/\n",
    "\n",
    "\n",
    "## 3.1 Parameterized Convolutional Neural Networks\n",
    "Created a simple function that takes in a few parameters and creates a convolutional neural network model. Easiest way to replicate a CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createParameterizedConvolutionalNeuralNetwork(trainImages, numLayers, numFilters, kernelSize, maxPooling, dropoutValue, learningRate, numClasses):\n",
    "    # Create model object\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add the first layer with dropout\n",
    "    model.add(Conv2D(numFilters, kernel_size=(kernelSize, kernelSize),\n",
    "                       activation='relu', padding = 'same',\n",
    "                     input_shape=trainImages.shape[1:]))\n",
    "    model.add(MaxPooling2D(pool_size=(maxPooling, maxPooling)))\n",
    "    model.add(Dropout(dropoutValue))\n",
    "    \n",
    "    while numLayers > 1:\n",
    "        model.add(Conv2D(numFilters, kernel_size=(kernelSize, kernelSize),\n",
    "                     activation='relu', padding = 'same'))\n",
    "        model.add(MaxPooling2D(pool_size=(maxPooling, maxPooling)))\n",
    "        model.add(Dropout(dropoutValue))\n",
    "        \n",
    "        numLayers = numLayers - 1\n",
    "        \n",
    "    # Convolutional layers are done, adding the remaining stuff. After Conv layers, you should always use a Flatten() layer.\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropoutValue))\n",
    "    model.add(Dense(numClasses, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(lr=learningRate),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Return model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 More Nuanced Convolutional Neural Networks\n",
    "In this section, I created a more nuanced model to comprae to the parameterized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNuancedConvolutionalNeuralNetwork(trainImages, numClasses):\n",
    "        # Create model object\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 8, kernel_size=(3, 3),\n",
    "                     activation='relu', padding = 'same',\n",
    "                     input_shape=trainImages.shape[1:]))\n",
    "    \n",
    "    model.add(Conv2D(filters = 8, kernel_size=(3, 3),\n",
    "                     activation='relu', padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters = 16, kernel_size=(3, 3),\n",
    "                     activation='relu', padding = 'same'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 16, kernel_size=(3, 3),\n",
    "                     activation='relu', padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    model.add(Conv2D(filters = 32, kernel_size=(3, 3),\n",
    "                     activation='relu', padding = 'same'))\n",
    "    model.add(Conv2D(filters = 32, kernel_size=(3, 3),\n",
    "                     activation='relu', padding = 'same'))\n",
    "    model.add(Conv2D(filters = 32, kernel_size=(3, 3),\n",
    "                     activation='relu', padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size=(3, 3),\n",
    "                     activation='relu', padding = 'same'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size=(3, 3),\n",
    "                     activation='relu', padding = 'same'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size=(3, 3),\n",
    "                     activation='relu', padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size=(3, 3),\n",
    "                     activation='relu', padding = 'same'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size=(3, 3),\n",
    "                     activation='relu', padding = 'same'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size=(3, 3),\n",
    "                     activation='relu', padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    # Convolutional layers are done, adding the remaining stuff. Reminder to add a Flatten() layer after the Convolutional layers.\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(numClasses, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Return model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Training\n",
    "## 4.1 Data Augmentation\n",
    "Deep learning models require huge amounts of data for good performance. With only around 5k examples, I will use what's called \"Data Augmentation\" to create more data. To read more on data augmentation, more info here: https://towardsdatascience.com/data-augmentation-for-deep-learning-4fe21d1a4eb9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#fce53a';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background('#fce53a')\n",
    "#Parameters here will give vastly different model performance results. For more info:\n",
    "# https://keras.io/preprocessing/image/\n",
    "# https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/\n",
    "dataAugmentation = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#fce53a';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background('#fce53a')\n",
    "\n",
    "#####################################################################################################################################################\n",
    "# Model Parameters for Parameterized and Nuanced Models - Some parameters are only for Parameterized Model                                                                                                           \n",
    "#####################################################################################################################################################\n",
    "numLayers = 2 # Number of layers in the neural network\n",
    "numFilters = 32 # Number of units in each layer\n",
    "kernelSize = 5 # filter size of a single filter\n",
    "dropoutValue = 0.4 # Dropout probability\n",
    "maxPooling = 2 # Max pooling\n",
    "numClasses = 2 # For MNIST since there are 10 classes i.e The model is trying to recognize a digit among 10 digits. For any other data set, this should be changed\n",
    "batchSize = 16 # How many images should a single batch contain\n",
    "learningRate = 0.0001 # How fast should the model learn\n",
    "epochs = 20 # Number of epochs to train the model for\n",
    "USE_DATA_AUGMENTATION = True # You can set it to false if you do not want to use data augmentation. We recommend trying both true and false.\n",
    "#####################################################################################################################################################\n",
    "\n",
    "\n",
    "# Training the augmentor in case we set USE_DATA_AUGMENTATION to True. This line needs to be here if data augmentation is enabled\n",
    "dataAugmentation.fit(trainData) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Your parameterized model has been created...\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "parameterizedModel = createParameterizedConvolutionalNeuralNetwork(trainData, numLayers, numFilters, kernelSize, maxPooling, dropoutValue, learningRate, numClasses = 2)\n",
    "print(\"+ Your parameterized model has been created...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Your non parameterized model has been created...\n"
     ]
    }
   ],
   "source": [
    "# You can create the other model with the following line\n",
    "nonParameterizedModel = createNuancedConvolutionalNeuralNetwork(imagesData, numClasses = 2)\n",
    "print(\"+ Your non parameterized model has been created...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################################################\n",
    "# Choose Parameterized or Non Parameterized - Nuanced Model                                                                                                         \n",
    "#####################################################################################################################################################\n",
    "\n",
    "# Please assign model the deep learning model you want to use i.e parameterizedModel or nonParameterizedModel\n",
    "model = nonParameterizedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 256, 256, 8)       80        \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 256, 256, 8)       584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 128, 128, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 4,427,802\n",
      "Trainable params: 4,427,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Model Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Starting training. Each epoch can take about 2-5 minutes, hold tight!\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Epoch 1/1\n",
      " - 121s - loss: 0.2919 - accuracy: 0.8946\n",
      "575/575 [==============================] - 6s 10ms/step\n",
      "+ Test accuracy at epoch 0 is: 93.04\n",
      "+ Writing kaggle test results in : results/epoch-0-results.csv...\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 114s - loss: 0.0835 - accuracy: 0.9669\n",
      "575/575 [==============================] - 6s 10ms/step\n",
      "+ Test accuracy at epoch 1 is: 93.74\n",
      "+ Writing kaggle test results in : results/epoch-1-results.csv...\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 119s - loss: 0.2932 - accuracy: 0.8886\n",
      "575/575 [==============================] - 6s 10ms/step\n",
      "+ Test accuracy at epoch 2 is: 91.83\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 111s - loss: 0.0796 - accuracy: 0.9695\n",
      "575/575 [==============================] - 5s 9ms/step\n",
      "+ Test accuracy at epoch 3 is: 94.96\n",
      "+ Writing kaggle test results in : results/epoch-3-results.csv...\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 121s - loss: 0.2780 - accuracy: 0.8912\n",
      "575/575 [==============================] - 6s 10ms/step\n",
      "+ Test accuracy at epoch 4 is: 93.39\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 110s - loss: 0.0771 - accuracy: 0.9704\n",
      "575/575 [==============================] - 6s 10ms/step\n",
      "+ Test accuracy at epoch 5 is: 92.87\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 120s - loss: 0.2782 - accuracy: 0.8986\n",
      "575/575 [==============================] - 6s 10ms/step\n",
      "+ Test accuracy at epoch 6 is: 93.39\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 112s - loss: 0.0688 - accuracy: 0.9756\n",
      "575/575 [==============================] - 5s 9ms/step\n",
      "+ Test accuracy at epoch 7 is: 94.61\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 120s - loss: 0.2869 - accuracy: 0.8973\n",
      "575/575 [==============================] - 5s 9ms/step\n",
      "+ Test accuracy at epoch 8 is: 94.78\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 113s - loss: 0.0658 - accuracy: 0.9787\n",
      "575/575 [==============================] - 6s 10ms/step\n",
      "+ Test accuracy at epoch 9 is: 93.91\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 120s - loss: 0.2758 - accuracy: 0.9016\n",
      "575/575 [==============================] - 5s 9ms/step\n",
      "+ Test accuracy at epoch 10 is: 89.74\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 112s - loss: 0.0652 - accuracy: 0.9761\n",
      "575/575 [==============================] - 5s 9ms/step\n",
      "+ Test accuracy at epoch 11 is: 93.22\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 119s - loss: 0.2808 - accuracy: 0.8994\n",
      "575/575 [==============================] - 6s 10ms/step\n",
      "+ Test accuracy at epoch 12 is: 94.26\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 113s - loss: 0.0585 - accuracy: 0.9769\n",
      "575/575 [==============================] - 6s 10ms/step\n",
      "+ Test accuracy at epoch 13 is: 93.91\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 121s - loss: 0.2706 - accuracy: 0.8951\n",
      "575/575 [==============================] - 6s 10ms/step\n",
      "+ Test accuracy at epoch 14 is: 93.74\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 113s - loss: 0.0574 - accuracy: 0.9778\n",
      "575/575 [==============================] - 6s 10ms/step\n",
      "+ Test accuracy at epoch 15 is: 95.13\n",
      "+ Writing kaggle test results in : results/epoch-15-results.csv...\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 121s - loss: 0.2636 - accuracy: 0.9042\n",
      "575/575 [==============================] - 6s 10ms/step\n",
      "+ Test accuracy at epoch 16 is: 92.52\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 112s - loss: 0.0594 - accuracy: 0.9791\n",
      "575/575 [==============================] - 6s 10ms/step\n",
      "+ Test accuracy at epoch 17 is: 95.30\n",
      "+ Writing kaggle test results in : results/epoch-17-results.csv...\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      " - 119s - loss: 0.2673 - accuracy: 0.8964\n",
      "575/575 [==============================] - 6s 10ms/step\n",
      "+ Test accuracy at epoch 18 is: 92.70\n",
      "\n",
      "\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "bestAcc = 0.0\n",
    "bestEpoch = 0\n",
    "bestAccPredictions, bestAccPredictionProbabilities = [], []\n",
    "\n",
    "print(\"+ Starting training. Each epoch can take about 2-5 minutes, hold tight!\")\n",
    "print(\"-----------------------------------------------------------------------\\n\")\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #################################################### Model Training ###############################################################\n",
    "    if USE_DATA_AUGMENTATION == True:\n",
    "        # Use data augmentation in alternate epochs\n",
    "        if epoch % 2 == 0:\n",
    "            ############ Can change the \"epoch % 2\" to some other integer value to train on top of the augmented data \n",
    "            ############ after a certain number of epochs e.g \"epoch % 3\" will train on augmented data after every 2 epochs ############\n",
    "            model.fit_generator(dataAugmentation.flow(trainData, trainLabels, batch_size=batchSize),\n",
    "                        steps_per_epoch=len(trainData) / batchSize, epochs=1, verbose = 2)\n",
    "        else:\n",
    "            model.fit(trainData, trainLabels, batch_size=batchSize, epochs=1, verbose = 2)\n",
    "    else:\n",
    "        # Do not use data augmentation\n",
    "        model.fit(trainData, trainLabels, batch_size=batchSize, epochs=1, verbose = 2)\n",
    "    \n",
    "    \n",
    "    #################################################### Model Testing ###############################################################\n",
    "    # Calculate test accuracy\n",
    "    accuracy = round(model.evaluate(testData, testLabels)[1] * 100, 3)\n",
    "    predictions = model.predict(testData)\n",
    "    print(\"+ Test accuracy at epoch %d is: %.2f\" % (epoch, accuracy))\n",
    "    \n",
    "    if accuracy > bestAcc:\n",
    "        bestEpoch = epoch\n",
    "        bestAcc = accuracy\n",
    "        bestAccPredictions = [1 if item[1] > item[0] else 0 for item in predictions]\n",
    "        bestAccPredictionProbabilities = predictions\n",
    "        \n",
    "        ##################################### Store predictions for kaggle ###########################################################\n",
    "        kaggleResultsFileName = \"epoch-\" + str(epoch) + \"-results.csv\"\n",
    "        getKagglePredictions(model, kaggleTestImages, kaggleResultsFileName)\n",
    "        ##############################################################################################################################\n",
    "    print('\\n')\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "##################################################### Printing best metrics ##########################################################\n",
    "print(\"\\n*** Printing our best validation results that we obtained in epoch %d ...\" % bestEpoch)\n",
    "calculateMetricsAndPrint(bestAccPredictions, bestAccPredictionProbabilities, testLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Top n% Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Accuracy for top 5 percent predictions for healthy: 100.00, pneumonia: 100.00\n",
      "+ Accuracy for top 10 percent predictions for healthy: 100.00, pneumonia: 100.00\n",
      "+ Accuracy for top 20 percent predictions for healthy: 100.00, pneumonia: 100.00\n",
      "+ Accuracy for top 30 percent predictions for healthy: 100.00, pneumonia: 100.00\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8MAAAHsCAYAAAD2EH/8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeZhVxb2v8bcYm6GhQYgMUQZBEXBEOSiigiIaruAcJBDRc3BIIleJBsEkmiNXiQlej0M8evSiNCJC1KgIzqBGHIJxVqIQnFBUBGSWoev+sbt3enYDPa/38zz90Luq9lq/3rTr8UutVRVijEiSJEmSlCT1qrsASZIkSZKqmmFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQlToPqLqA6hRBcSluSJEmS6rgYYyje5sywJEmSJClxEj0zXMC9liVJkiSp7gmhxIRwmjPDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJSpwG1V2Ayhbz8tixYkVGY+t37Eio579tSEnl9UJSJrxWSMpEUq4VVR6GQwjdgMuBfkBv4IUY47HFxgRgInAR0Ab4GzAuxvhGsXE9gZuBI4C1wJ3A72KMOyr5x6gSO1asYMVBB6Vfv936AB7tegZrG+eQ891ahi2bQ+817wDQ8c03abDXXtVVqqRq5vVCUia8VkjKRFKuFdUxM9wL+BHwMtCojDFXAL8hFZqXAOOBp0MIvWOMKwFCCK2Ap4H3gOHAPsBUUrd+/7oyf4Cq9l29RlzR/0bmdzqZLQ2bpdun9ziPkz5+lCkvXlKN1UmqSbxeSMqE1wpJmajr14rqCMOPxhgfBggh/JnUzG9aCCGLVBi+LsZ4S37bS8BHwC/4V9C9EGgCnBZjXAc8FUJoAVwdQrg+v61OuKL/jTzUbUSJ9i0Nm6XbZ1d1UZJqJK8XkjLhtUJSJur6taLKb+6OMeZ9z5AjgRYU+lxjjBuBR4GTCo07CXiiWOidRSogH1Mx1Va/t1sfwPxOJ5c7Zn6nk3njKx//lpLO64WkTHitkJSJJFwrQoyx+k6ePzNc+JnhEMLPgJuAxoWf/Q0hXA5cHWNslv/6K+BPMcarix1zY/64P2Rw/ghQnZ9BebZ/+ik///e/cMcBF1d3KZIkSZJUwvg+65g6skV1l1Gm1HJUEGMMxftq4rJfrYANpSyCtQZoGkJoVGjc2lLevya/r0whhPNDCIt3u9IqsLZxTnWXIEmSJEmlWrOlRMasNWpiGAYobao2lNJX1rhyp3pjjHfEGA/bxdqqVM53peV9SZIkSap+rbJq5l22maiJN3ivAbJDCPWLzQ7nAJtijNsKjStt2rQlpc8Y10rDls1heo/ziqzeVlzWto28cM46DuvTvgork1STbP/0U5449iecMXS+1wtJZfJaISkTO3OtOHu/jaSWfKp9auLM8BKgPtCtWHuP/L7C43oUHhBC2AtoVmxcrdZ7zTuc9PGj5Y456eNHOfgH26uoIkk1ldcLSZnwWiEpE0m4VtTEMLwIWAecWdAQQmgKnAzMLzRuPjAkhJBdqO3HwGbguSqos8pMefESTl06i6xtG4u0Z23byKlLZ9X6/b0kVRyvF5Iy4bVCUibq+rWiyleTzg+2P8p/+UtSc+pX5b+eF2PcFEKYCPwGuJzULO944N+AXjHGL/OP0wp4D3gH+D3QFbgBuDHGWLAX8ffVUqNXk455eexYsSL9+o2vGnDfP5qxZkugVVbk7P02pv8lpn7HjoR6NfHfNiRVBa8XkjLhtUJSJurStaK81aSrIwx3BpaX0d0lxvhRSFU8CbgI2ANYDIyLMb5e7Fg9gVuAI0g9J3wnqW2Viq9EXVYtNToMS5IkSZJ2XY0KwzWJYViSJEmS6q7ats+wJEmSJEmVyjAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUqcGhuGQwgjQgh/DyFsCCGsCCFMDyF0KDYmhBAmhRA+DSFsDiE8H0I4uLpqliRJkiTVDjUyDIcQhgH3AYuA4cAE4GhgbgihcM1XAL8Bfg+cDGwAng4htKvaiiVJkiRJtUmIMVZ3DSWEEGYB3WOMfQq1DQMeBnrGGN8PIWQBXwJTY4z/mT+mGfARcHuM8dcZnCcC1MTPQJIkSZK0e0IIAMQYQ/G+GjkzDDQEvi3Wtjb/z4If4kigBTC7YECMcSPwKHBSZRcoSZIkSaq9amoY/n/AgBDCT0MILUII+wKTgQUxxvfyx/QAdgAfFnvv+/l9kiRJkiSVqkaG4RjjY8AY4A5SM8T/AOoDpxUa1grYEGPcUezta4CmIYRGZR0/hHB+CGFxhRYtSZIkSao1amQYDiEMBP4b+C9gIDACaA08FEKoX2hoaQ/7hnL6Uh0x3hFjPKyCypUkSZIk1TINqruAMkwFHokxTihoCCG8ASwhtbr0g6RmgLNDCPWLzQ7nAJtijNuqsmBJkiRJUu1RI2eGST3z+0bhhhjjP4DNwD75TUtI3TrdrZT3LqnsAiVJkiRJtVdNDcMfA4cWbggh7A80IbV1EqT2IF4HnFloTFNS+w3Pr5IqJUmSJEm1Uk29Tfq/gf8bQvicVLDdE/gtqSA8DyDGuCWEMAX4TQhhDanZ4PGkAv7N1VG0JEmSJKl2qKlh+CZgK3ARcCGpPYb/CkzM30u4wBRS4XcisAewGBgcY/yyasuVJEmSJNUmIcYyF12u80IIESDJn4EkSZIk1VUhpDYbijGG4n019ZlhSZIkSZIqjWFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQljmFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQljmFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQljmFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQljmFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQljmFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQljmFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQljmFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQljmFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQljmFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQljmFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQljmFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQljmFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQljmFYkiRJkpQ4hmFJkiRJUuIYhiVJkiRJiWMYliRJkiQljmFYkiRJkpQ4hmFJkiRJUuJkFIZDCP8rhGBwliRJkiTVCZkG3IeBFSGE34cQ9q/MgiRJkiRJqmyZhuF9gDuAs4B3QggvhRDGhhBaVF5pkiRJkiRVjhBj3Lk3hDAIOBc4FQjAg8D/izEuqPjyKlcIIQLs7GcgSZIkSar5QggAxBhDib5dDYIhhA7ALOAoIAKfADcBN8cYt+9qsVXJMCxJkiRJdVd5YXinF8UKIRwTQrgb+AfQG7gVOAGYA/wOmL4btUqSJEmSVOkymhkOIXQCzsn/6gwsBO4EHowxfldo3KnAjBhjs8ootqI5MyxJkiRJdVdFzAz/ExgLzAS6xRiPizHeVzgI53sXeHU3ak0LITQIIVwRQvgwhPBdCOGzEML/LTYmhBAmhRA+DSFsDiE8H0I4uCLOL0mSJEmquxpkOO5k4PEYY155g2KMHwADd7uqlGnAcaRuvV4C7AX0LDbmCuA3wOX5Y8YDT4cQescYV1ZQHZIkSZKkOibT26SzgeYxxi9K6WsPrI8xbqiwokI4EXgUOCjG+F4ZY7KAL4GpMcb/zG9rBnwE3B5j/HUG5/E2aUmSJEmqoyriNum7gP8so+9qUs8PV6TzgGfLCsL5jgRaALMLGmKMG0mF6JMquB5JkiRJUh2SaRg+GnisjL55+f0V6d+AD0IIt4QQ1oUQNoUQHszfzqlAD2AH8GGx976f3ydJkiRJUqkyDcMtgU1l9G0BWlVMOWntgDHAwcAI4FygD/BQKJjnTp1zQ4xxR7H3rgGahhAalXXwEML5IYTFFVyzJEmSJKmWyHQBrQ+BocCTpfT9CFhWYRWlhPyv4THGbwBCCF8AzwGDgGfyx5X2sG8opy/VEeMdwB0FzwxLkiRJkpIl0zB8M/DfIYStwN3AF0B7UvsO/xy4qILrWgP8syAI5/srsJXUitLP5I/JDiHULzY7nANsijFuq+CaJEmSJEl1REZhOMb4PyGEPYGJpLYvKrAF+HWM8X8quK73gcaltAegYHunJUB9oBvwj0JjeuT3SZIkSZJUqkyfGSbGOBnoQOp26Z/m/9khxjilEuqaCxwYQmhTqO1ooCHwZv7rRcA64MyCASGEpqT2RJ5fCTVJkiRJkuqIjPYZrmohhBbAO8AK4FogG/g9sCTGOLjQuInAb4DLSc0Gjye1EnWvGOOXGZzHfYYlSZIkqY4qb5/hTJ8ZJn8V5/7AvkBW8f4Y4592vcQSx1oXQhgE3ATMIvWs8MPApcWGTiE1uz0R2ANYDAzOJAhLkiRJkpIro5nh/OeFnyG1eFWklBWbY4z1K6PAyuTMsCRJkiTVXeXNDGf6zPBU4FtgL1JB+N+AzqRuUf6Q1GyxJEmSJEm1Qqa3SR8D/G9SWypBakb5E+DaEEI94E/AkEqoT5IkSZKkCpfpzHAO8HWMMY/UCs4/KNS3CDiyoguTJEmSJKmyZBqGlwPt879/F/hJob6TgdUVWZQkSZIkSZUp09uk5wEnALOBycDDIYTPgG3A3sCEyilPkiRJkqSKt0v7DIcQDgNOBZoAT8UY51d0YVXB1aQlSZIkqe4qbzXp7w3DIYTGwGXA3Bjjm5VRYHUxDEuSJElS3bVbWyvFGL8DriS1iJYkSZIkSbVepgtovQL0qcxCJEmSJEmqKpkuoPUrYGYIYSupxbS+BIrcWxxj3FTBtUmSJEmSVCkyWkArhJBX6GWpb4gx1q+ooqqKzwxLkiRJUt1V3jPDmc4Mn0cZIViSJEmSpNpml7ZWqiucGZYkSZKkumu3VpOWJEmSJKmuyeg26RDC13zPbdIxxh9USEWSJEmSJFWyTJ8ZvpWSYbg1MAhoAdxVkUVJkiRJklSZMgrDMcarS2sPqRuwZwPbK7AmSZIkSZIq1W49MxxTK0/dCfyiYsqRJEmSJKnyVcQCWl2BRhVwHEmSJEmSqkSmC2j9rJTmRsD+wE+AORVZlCRJkiRJlSmjfYZDCHmlNH8HfAY8BPwuxrixgmurdO4zLEmSJEl1V3n7DGe6gJb7EUuSJEmS6gxDriRJkiQpcTIKwyGE/xNCuL2Mvv8OIVxTsWVJkiRJklR5Mp0ZPht4oYy+F4CRFVOOJEmSJEmVL9Mw3AFYUUbf5/n9kiRJkiTVCpmG4ZXAoWX0HQp8XTHlSJIkSZJU+TINw7OB34YQhhZuDCH8CPgNMKuiC5MkSZIkqbJkus9wFvAIcDzwDfAF0B5oDTwJnBJj/K4S66wU7jMsSZIkSXVXefsMZxSGCx1oCDAQ2INUKH4mxvhUxZRZ9QzDkiRJklR3VVgYrmsMw5IkSZJUd5UXhjPdZ3hECOHyMvouCyGctVsVSpIkSZJUhTJdQOsKYEsZfZuAiRVTjiRJkiRJlS/TMNwdeKeMvvfz+yVJkiRJqhUyDcObgB+W0bcXUOtWkpYkSZIkJVemYfhp4DchhB8UbgwhtAWuJLW9kiRJkiRJtUKm+wzvDbwMZAOP8699hocA3wJHxhg/rcQ6K4WrSUuSJElS3VUhWyvlzwKPp9g+w8ANwLoY47YKqrfKGIYlSZIkqe6qlH2GQwj1gGOBs4HTYox77HqJ1cMwLEmSJEl1V3lhuMEuHOzfSAXgs4A9gdXArN0rUZIkSZKkqpNRGA4h9CYVgEcAnYGtQCNSt03fGmPcXlkFSpIkSZJU0cpcTTqE0DWEMCmE8DbwJnAZqT2Ff0pqX+EAvG4QliRJkiTVNuXNDC8FIvAKcAHwQIxxDUAIoWUV1CZJkiRJUqUob5/hj0nN/vYmtVDWkSGEnX7GWJIkSZKkmqbMMBxj7AL0B+4BjgMeBb4MIfxP/muXYJYkSZIk1UoZba2Uv43ScaQW0ToFyCEVhmcC/xVjXFyZRVYWt1aSJEmSpLqrQvcZDiE0An5EamXp/wU0AT6IMe6/25VWMcOwJEmSJNVdFRqGix24GamZ4hExxpN3+UDVxDAsSZIkSXVXpYXh2s4wLEmSJEl1V3lhuLzVpCVJkiRJqpMMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxDEMS5IkSZISxzAsSZIkSUocw7AkSZIkKXFqfBgOIXQMIWwIIcQQQvNC7SGEMCmE8GkIYXMI4fkQwsHVWaskSZIkqXao8WEY+AOwoZT2K4DfAL8HTs4f83QIoV0V1iZJkiRJqoVqdBgOIQwATgT+WKw9i1QYvi7GeEuM8WngTCACv6jyQiVJkiRJtUqNDcMhhPrAzcB/AquKdR8JtABmFzTEGDcCjwInVVWNkiRJkqTaqcaGYeBCIAu4tZS+HsAO4MNi7e/n90mSJEmSVKYG1V1AaUIIewDXAKNijNtCCMWHtAI2xBh3FGtfAzQNITSKMW6tglIlSZIkSbVQTZ0Z/j/AKzHGeeWMiaW0hXL6/jUohPNDCIt3tThJkiRJUu1W42aGQwi9gPOAo0MIOfnNTfP/bBlC2EFqBjg7hFC/2OxwDrApxritvHPEGO8A7gghlBuaJUmSJEl1U40Lw0B3oCHwUil9nwF3ATOB+kA34B+F+nsASyq7QEmSJElS7VYTw/BfgYHF2k4EJgA/Av4JfAysI7Wd0mSAEEJTUvsN31FllUqSJEmSaqUaF4ZjjKuAhYXbQgid8799Ica4Ib9tCvCbEMIaUrPB40k9A31zVdUqSZIkSaqdalwY3glTSIXficAewGJgcIzxy2qtSpIkSZJU44UYk7uGVMECWkn+DCRJkiSprirYpjfGWGK/3pq6tZIkSZIkSZXGMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJSpwaGYZDCGeGEB4JIawIIWwIIbwWQji7lHFjQwgfhhC25I85rjrqlSRJkiTVLjUyDAPjgQ3ApcAwYAEwM4RwccGAEMII4L+B6cBJwLvA3BBC76ovV5IkSZJUm4QYY3XXUEIIoU2McVWxtpnAETHGLvmv/wG8GGM8L/91PeBN4M0Y46gMzxMBauJnIEmSJEnaPSEEAGKMoXhfjZwZLh6E870O/AAghNAV2BeYXeg9ecAcUrPEkiRJkiSVqUaG4TIcCbyX/32P/D+XFBvzPtA6hNC2yqqSJEmSJNU6tSIM5y+MNRy4Nb+pVf6fa4sNXVOsX5IkSZKkEmp8GA4hdAZmAg/HGO8u1l38Yd9QRnvxY54fQlhcEfVJkiRJkmqfGh2GQwitgfnAJ0DhRbEKZoBzir2l4HXxGeMiYox3xBgPq5AiJUmSJEm1To0NwyGEpsBcoBEwNMa4sVB3wbPCPYq9rQewOsb4dRWUKEmSJEmqpWpkGA4hNCC1MnR34KQY41eF+2OM/wQ+AM4s9J56+a/nV2GpkiRJkqRaqEF1F1CGPwE/Av43qdWh+xXqez3G+B1wNTAjhPAR8CJwDqnwPLJqS5UkSZIk1TYhxnLXmqoW+QG3UxndXWKMH+WPGwtMAPYC3gUujzE+sxPniQA18TOQJEmSJO2eEFJrLMcYQ4m+JAdBw7AkSZIk1V3lheEa+cywJEmSJEmVyTAsSZIkSUocw7AkSZIkKXEMw5IkSZKkxKmpWyvVODFGduzY4WJbktJCCNSvXz+9MIMkSZJqD8Pw94gxsmnTJgAaNGhAvXpOpktK2bFjB9999x0ATZs2NRRLkiTVIm6tRPlbK23cuJEmTZoYgiWVKS8vj82bN9OsWbPqLkWSJEmFuLXSLioIyQZhSeUpuEYk+R8XJUmSahtTXjl27NhBgwbeSS7p+zVo0IAdO3ZUdxmSJEnKkGG4HDFGZ4UlZSSE4MywJElSLWLSk6QK4OJZkiRJtYthWJIkSZKUOIZhqQI9++yzHHbYYeltdt54443qLqnSXX311RnPii5cuJAQAjNmzKjkqiRJkqTyGYaV9sADDxBCoE2bNmzbtq26y6l11q5dy+mnn05eXh433XQTubm5dOrUqVLP2blzZ44//vhS+z766CNCCEyePLlSayjN3XffzU033VTl55UkSZIy5VLJSpsxYwZdunRh+fLlzJ8/n2HDhlV3SbXK4sWLWbt2Lb/97W855ZRTqrucanX33Xfz2WefMW7cuOouRZIkSSqVYbiKxLw8dqxYkdHY+h07Eqp4FevVq1czb948brjhBqZNm0Zubm6NDsMbN26kWbNm1V1GEV999RUAOTk5FXbMzZs307hxY1c1lyRJkiqY/4ddRXasWMGKgw7K6CvT0FyR7r//fvLy8jjrrLMYOXIkjz76KGvXri117IIFCzjhhBPIycmhWbNmHHDAAVx33XVFxixbtozRo0fTvn17GjduTJcuXRg7dizr168HUjOHIQQ++uijIu8ruLX37rvvTreNGTOGBg0a8Omnn3LaaaeRk5PDUUcdBcDbb7/NeeedR7du3WjSpAmtW7dm+PDhvPfeeyXq3rZtG1OmTKFXr15kZWXRtm1bBg8ezAsvvABAv3796NWrV6k/80knncTee+9NXl5eqf3HHnssP/nJTwAYOHAgIQSOPfbYdP+LL77IcccdR3Z2Ns2bN+e4447jpZdeKnKMgs/k6aefZvz48XTo0IFmzZqxbt26Us+5q9avX8+vfvUrunTpQqNGjdh77725/PLL2bx5c4l6Bg8eTPv27WnUqBFdu3Zl4sSJfPfdd+Uev3Pnzjz33HMsW7aMEAIhBDp37lxkTIyRqVOn0qlTJ7KysujXrx9///vf0/2PP/44IQRmz55d4vivvPIKIQTuvPPOXf8QJEmSlHjODAuA3Nxcjj/+eNq2bcuIESO4/PLLmTNnDmPHji0ybubMmYwePZquXbty6aWXsueee7JkyRIefvhhJk6cCMD7779P//792b59O+effz777rsvn332GQ899BDffPMN2dnZO11fjJEhQ4Zw4IEHMmXKlHQoffLJJ3nvvfcYNWoUHTt25LPPPuP2229nwIABvPvuu7Rr1w6AvLw8TjnlFObNm8ewYcO44IIL2LZtG4sWLeL5559nwIABjBkzhosuuojXXnuNPn36pM/95Zdf8tRTT/GrX/2qzMUnfQQAACAASURBVBnaK6+8kp49e3LbbbcxadIk9t9/f/bcc08Ann/+eQYPHkyHDh2YNGkSALfffjsDBw7kmWeeoX///kWOdckll5Cdnc2ECRPYtGkTjRo1Kvez2bZtG6tWrSrRvmbNmhJtW7ZsYdCgQXz44Yecf/75dOvWjbfeeosbb7yRd955h3nz5qUXw7r11lvZb7/9GDJkCM2bN2fRokVcf/31fPLJJ9x7771l1nPjjTcyceJE1qxZwx//+EcAmjdvXmTMf/3Xf/Hdd98xbtw4tm/fzh/+8AdOPfVUli5dSsOGDdOfV25uLmeddVaR9+bm5pKVlcWZZ55Z7uciSZIklSvGmNgvIKY+gtJt3bo1bt26tcz+nbHtk0/iR61aZfS17ZNPKuScmVq6dGkEYm5ubrpt0KBBccCAAUXGrVu3LrZs2TL27t07rl+/vkhfXl5e+vuBAwfGrKys+P7775c4V8G4adOmRSAuX768SP/y5csjEKdNm5ZuO+eccyIQL7744hLH27hxY4m2Dz/8MDZu3DhOnjw53XbPPfdEIF511VVl1rRmzZqYlZUVx40bV6R/6tSpESj15yksNzc3AnHBggVF2vv06RNzcnLiypUr022ff/55bNGiRTz88MPTbQWfyaGHHprx712nTp1iwe9xWV/XXHNNevy1114bGzduHN96660ix7n99tsjEJ988sl0W2mf7TXXXBNDCPHTTz9Nt1111VUl/js65phj4j777FPi/QsWLIhA7NKlS9y0aVO6/aGHHopAnDt3brptwoQJsUGDBvGrr75Kt23dujW2adMm/vjHP87k46lSFXm9kCRJUsUolPlK5EFvkxa5ubk0bdq0yKJPI0eO5K9//WuR25iffPJJvv32WyZOnFhipq9gNnHVqlUsXLiQ0aNH06NHjxLnynQLntL87Gc/K9HWtGnT9PcbN27km2++IScnh3333ZfXXnst3Tdnzhyys7O54ooryqwpJyeH4cOHc99997F9+/Z0f25uLocffnipP8/3WblyJa+99hqjR49OzxQDtG/fnlGjRvG3v/2NL7/8ssh7xo4dS8OGDTM+xyGHHMJTTz1V4qu07Yvuv/9+jjjiCNq3b8+qVavSXwUrUj/77LPpsQWfbV5eHmvXrmXVqlUcffTRxBiL3NK8K8aMGUOTJk3Sr4855hgA/vnPfxYZs337du67775027x581i1ahU//elPd+v8kiRJkrdJixkzZnDUUUexcuXKdNtBBx1EvXr1mDFjBr/+9a8BWLp0KQAHHHBAmcdatmwZMcZyx+yqrl27lmj79ttvmTRpEnPmzOHrr78u0temTZv090uXLqV79+5kZWWVe45zzz2X+++/nyeeeIKhQ4fyzjvv8MYbb3DLLbfsUs0F/5hQWpDu2bNnekzhoLzPPvvs1Dlat25d6vZKxZ/HBvjggw/YvHkzbdu2LfVYBYuAAbz88stMmjSJRYsWlXhOuKznyTNVfMupVq1aAamF3Ar06NGDfv36kZubm16VOjc3l3bt2jFkyJDdOr8kSZJkGE64RYsWsWzZMpYtW0b37t1L9Ofm5qbDcOoug/JndzMZU17/jh07Sm2vX79+qc/OjhgxgoULFzJ+/HgOPfRQsrOzqVevHpdcckmRxa5ijBnNSg8ePJiOHTsyffp0hg4dyvTp02nYsCEjRoz43vfurLI+q8IzphUtLy+PY445Jv13WlyHDh0AWL58OYMGDWKfffYpstDVihUrGDNmTJkLiWWqfv36pbYXfCYFxowZw4UXXsj7779Pu3btmDt3Lj//+c/LfL8kSZKUKcNwwuXm5tK8eXOmTZtWou/NN99k8uTJvPrqq/Tt2zcdlt966y169+5d6vG6deuWHlOegpnA4jOMpc1mlmXt2rU8/vjjXH311Vx11VVF+tasWVNkZrh79+4899xzbNmypdzZ4Xr16jF69GhuvPFG1qxZw8yZMxk6dCh77LFHxnUVVrCK8pIlS0r0FbQVnyWtTN26dWPdunWlziQX9sgjj7B582bmzp1bpL4nn3wyo/Pszu3whY0YMYJLLrmE3NxcOnXqxHfffect0pIkSaoQPjOcYFu3bmX27NmceOKJnHHGGSW+JkyYQOPGjcnNzQXghBNOoGXLllx33XVs2LChyLEKZvTatGnDwIEDmT59eqkBsGBcQWhesGBBkf5bb7014/oLZgeLz1LOmDGDzz//vEjbmWeeyfr165kyZUqZNRUYM2YMW7Zs4aKLLmLFihW7Fb7atWvHYYcdRm5ubpFbkFeuXElubi59+/Ytcot0ZRsxYgSvv/46Dz74YIm+LVu2pLe+Klg1u/Bnm5eXx9SpUzM6T7NmzXb7VmqAli1bcsopp3Dvvfdyzz33cOCBB3LQQQft9nElSZIkZ4YT7LHHHmP16tUMGzas1P7mzZszaNAgZs2axQ033EB2djY333wz55xzDocccgijR4+mXbt2fPDBByxatIhFixYBcPPNN9O/f3/69u3L+eefz3777ccXX3zBgw8+yF/+8hc6d+5Mz549Oeqoo7jyyitZvXo1e+65J4888kip2wGVJTs7m4EDB3L99dezZcsW9tlnHxYvXsyf//znEs8Xjxo1ipkzZ/K73/2ON954g+OOO44dO3awaNEiDj744PSWRwD77bcfRxxxBPfffz977LEHQ4cO3YVP91+mTp3K4MGD6devHxdccAExRm6//Xa2bNnCDTfcsFvH3lmXXXYZc+fO5cwzz2TUqFH07duXbdu28cEHHzB79mz+/Oc/c+yxx3LiiSfSuHFjhg4dygUXXEBeXh6zZ8/+3j2GC/Tp04fHHnuMyy67jD59+tC8eXNOPvnkXar53HPPZdasWXzyyScZh3FJkiTp+xiGEyw3N5f69euXG/aGDx/O/Pnzefzxxzn55JPTAfi6667jD3/4A3l5eXTt2pVRo0al39OrVy9effVVrrrqKu655x7Wr19Phw4dGDx4cJFbl2fMmMGFF17I1KlTadq0KWeffTYXXXQRvXr1yvhnmDlzJuPHj+euu+5iy5Yt9O3bl6eeeopf/vKXRcbVq1ePhx9+mOuvv54ZM2Ywf/58WrRowaGHHppeybiwMWPG8NJLLzFixIjv3ef3+xx99NE888wz/Pa3v+Waa64BoG/fvtx7770ceeSRu3XsnZWVlcWzzz7L9ddfz6xZs5g1axbNmzenS5cu/OIXv+DAAw8EUreVP/LII0yaNImJEyfSokULzjjjDC688MKMFkcbP348S5Ys4a677ko/c7yrYfj444/nhz/8IV988QUjR47cpWNIkiRJxYXit4gmSQghtdlwGZ/Btm3bAHZqm5uyxLw8dqxYkdHY+h07Eup5B3t1mjZtGueddx6vvPIKffv2re5yEi3GSJcuXejZsyfz5s2r7nLKVJHXC0mSJFWMgrVsYowlFrVxZriKhHr1aLDXXtVdhjJ0xx130LNnT4NwDfDEE0/w8ccfc/3111d3KZIkSapDDMNSvo0bN/Loo4/y4osv8vLLL3PXXXdVd0mJ9sorr/DOO+9w7bXX0qVLF0477bTqLkmSJEl1iGFYyvf1119z9tln07JlS8aNG8eYMWOqu6REu+2225gxYwa9evXizjvvpEEDL1eSJEmqOD4zTNU8MyypbvN6IUmSVPOU98ywqzRJkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLkiRJkhLHMCxJkiRJShzDsCRJkiQpcQzDkiRJkqTEMQxLFejZZ5/lsMMOo2nTpoQQeOONN6q7JJVh4cKFhBBYuHBhdZciSZKkamAYVtoDDzxACIE2bdqwbdu26i6n1lm7di2nn346eXl53HTTTeTm5tKpU6dKPWfnzp0JIaS/mjZtyiGHHMLNN99MXl5epZ5bkiRJqs0aVHcBqjlmzJhBly5dWL58OfPnz2fYsGHVXVKtsnjxYtauXctvf/tbTjnllCo7b69evbjiiisA+Oqrr7jnnnsYN24cX3zxBddee22V1VHbHH300WzevJlGjRpVdymSJEmqBs4MC4DVq1czb948fvnLX9KnTx9yc3Oru6Rybdy4sbpLKOGrr74CICcnp8KOuXnz5u+d4W3Xrh2jRo1i1KhRjB8/nkWLFvHDH/6Qm266yRn+ctSrV4+srCzq1fMyKEmSlET+X2A1+funcPmj8O/3p/58/bPqref+++8nLy+Ps846i5EjR/Loo4+ydu3aUscuWLCAE044gZycHJo1a8YBBxzAddddV2TMsmXLGD16NO3bt6dx48Z06dKFsWPHsn79egDuvvtuQgh89NFHRd730UcfEULg7rvvTreNGTOGBg0a8Omnn3LaaaeRk5PDUUcdBcDbb7/NeeedR7du3WjSpAmtW7dm+PDhvPfeeyXq3rZtG1OmTKFXr15kZWXRtm1bBg8ezAsvvABAv3796NWrV6k/80knncTee+9dZjA99thj+clPfgLAwIEDCSFw7LHHpvtffPFFjjvuOLKzs2nevDnHHXccL730UpFjFHwmTz/9NOPHj6dDhw40a9aMdevWlXrOsjRr1ox+/fqxceNGvv7663R93bp1Y+nSpQwZMoRmzZrxgx/8gCuuuKLUn2nOnDn069ePpk2b0qJFC4YOHcrbb79dZMyYMWPo3LlzifeW9nfbuXNnjj/+eF5++WWOPPJImjZtSrdu3ZgzZw4Ar776KgMGDKBp06Z06tSJe+65p8RxP/30U0aNGkXbtm3JysrioIMOKvJ7Av/6/Zk8eTLTp0+nR48eNG7cmAMOOICnnnqqyNjSnhnemd8nSZIk1W7eJl3FvtsO/zEbHngLNheatLv1RTj9QLjzLGhcDX8rubm5HH/88bRt25YRI0Zw+eWXM2fOHMaOHVtk3MyZMxk9ejRdu3bl0ksvZc8992TJkiU8/PDDTJw4EYD333+f/v37s337ds4//3z23XdfPvvsMx566CG++eYbsrOzd7q+GCNDhgzhwAMPZMqUKekA9+STT/Lee+8xatQoOnbsyGeffcbtt9/OgAEDePfdd2nXrh0AeXl5nHLKKcybN49hw4ZxwQUXsG3bNhYtWsTzzz/PgAEDGDNmDBdddBGvvfYaffr0SZ/7yy+/5KmnnuJXv/pVmbOIV155JT179uS2225j0qRJ7L///uy5554APP/88wwePJgOHTowadIkAG6//XYGDhzIM888Q//+/Ysc65JLLiE7O5sJEyawadOmXbqNd9myZdSvX7/ILPX69es5/vjjOemkkzj11FN54okn+P3vf0+XLl244IIL0uP++Mc/cvnll3PqqacyevRoNmzYwG233Ub//v1ZvHgx++67707XA/Dxxx9z6qmnct5553H22Wfzpz/9iREjRhBjZNy4cfz7v/87P/7xj7n11ls599xz6devH/vttx8Aq1at4sgjj+Sbb77h4osvpmPHjsyePZtzzz2XVatWcdlllxU511/+8he+/vprLrzwQpo0acKNN97IqaeeyieffELr1q3LrDHT3ydJkiTVATHGxH4BMfURlG7r1q1x69atZfbvilH3xsj4sr9G3Vuhp8vI0qVLIxBzc3PTbYMGDYoDBgwoMm7dunWxZcuWsXfv3nH9+vVF+vLy8tLfDxw4MGZlZcX333+/xLkKxk2bNi0Ccfny5UX6ly9fHoE4bdq0dNs555wTgXjxxReXON7GjRtLtH344YexcePGcfLkyem2e+65JwLxqquuKrOmNWvWxKysrDhu3Lgi/VOnTo1AqT9PYbm5uRGICxYsKNLep0+fmJOTE1euXJlu+/zzz2OLFi3i4Ycfnm4r+EwOPfTQjH/vOnXqFI8++uj49ddfx6+//jq+++678ec//3kE4vDhw9PjjjnmmAjE2267rcj7DzrooHjYYYelX3/yySexQYMGcdKkSUXGrVy5MrZq1SqOHDky3XbOOefETp06laiptL/bTp06RSA+9dRT6bb33nsvAjGEEJ955pkS7RMmTEi3/fKXv4xAfPzxx9NtW7dujUcccUTMysqKq1atijH+6/enRYsWRT7v119/PQLxlltuSbctWLCgxN9Xpr9PpamM64UkSZJ2T6HMVyIPept0Ffr7p6kZ4fI88Ba8vqJq6imQm5tL06ZNiyz6NHLkSP76178WudX1ySef5Ntvv2XixIk0b968yDFCCEBqBm/hwoWMHj2aHj16lDhXwbhd8bOf/axEW9OmTdPfb9y4kW+++YacnBz23XdfXnvttXTfnDlzyM7OTi80VVpNOTk5DB8+nPvuu4/t27en+3Nzczn88MNL/Xm+z8qVK3nttdcYPXp0eqYYoH379owaNYq//e1vfPnll0XeM3bsWBo2bJjxOZ5//nnatm1L27Zt6dWrF3/6058YNmwYd911V5FxDRs25D/+4z+KtB1zzDH885//TL9+4IEH2L59O2effTarVq1Kf9WvX58jjjiCZ599dmd+/CK6du3K8ccfn369//7707JlS7p06cKgQYNKtBeua+7cufTu3ZshQ4YU+XkuvfRStmzZwjPPPFPkXKeffnqRz/vggw+mRYsWRY5Zmkx/nyRJklT7eZt0FbrvjaK3Rpdm8za47+9wSMeqqQlSq0gfddRRrFy5Mt120EEHUa9ePWbMmMGvf/1rAJYuXQrAAQccUOaxli1bRoyx3DG7qmvXriXavv32WyZNmsScOXPSz8cWaNOmTfr7pUuX0r17d7Kysso9x7nnnsv999/PE088wdChQ3nnnXd44403uOWWW3ap5oJ/TCgtSPfs2TM9pnBw22effXbqHIcccgjXX389IQSaNGnCvvvuW+RnL9CxY0caNCj6n3yrVq1YvXp1+vUHH3wAlP13vDuLTe29994l2nJycspsX7NmTfr1Rx99VOrq5gWf4fLly4u0l7alVfGftTSZ/j5JkiSp9jMMV6HVmyp2XEVYtGgRy5YtY9myZXTv3r1Ef25ubjoMp+4yKH92N5Mx5fXv2LGj1Pb69euX+uzsiBEjWLhwIePHj+fQQw8lOzubevXqcckllxRZGCrGmNGs9ODBg+nYsSPTp09n6NChTJ8+nYYNGzJixIjvfe/OKuuzatKkyU4dp3Xr1kVmXMtSv3797x1T8JnNnTuXxo0blzt2V/4Od6a94PMpT1mf4a4eM9PfJ0mSJNV+huEq1Lrp94/ZmXEVITc3l+bNmzNt2rQSfW+++SaTJ0/m1VdfpW/fvumw/NZbb9G7d+9Sj9etW7f0mPK0atUKoMSK1cVXly7P2rVrefzxx7n66qu56qqrivStWbOmyExe9+7dee6559iyZUu5s8P16tVj9OjR3HjjjaxZs4aZM2cydOhQ9thjj4zrKqxgteUlS5aU6CtoK20Ws7oU/P3ttddeHHjggeWObdWqVakrju/M32GmOnfuXO5nWNqq1jtrZ36fJEmSVPv5zHAVGnkINPmeR0GbNISzD62aerZu3crs2bM58cQTOeOMM0p8TZgwgcaNG6f3HD7hhBNo2bIl1113HRs2bChyrIIZtzZt2jBw4ECmT59eangpGFcQuhYsWFCk/9Zbb824/oLZv+IzdjNmzODzzz8v0nbmmWeyfv16pkyZUmZNBcaMGcOWLVu46KKLWLFiBT/96U8zrqm4du3acdhhh5Gbm5vehxhSzxLn5ubSt2/fIrdIV7fTTz+dBg0acNVVV5U6E1r41uFu3brx7bff8vrrr6fbNmzYUOq2SLvr5JNP5u233y6yPdL27du58cYbycrKymhm/PvszO+TJEmSaj9nhqvQIT9MbZ80o5x1eE4/sOqeF37sscdYvXp1qc9iAjRv3pxBgwYxa9YsbrjhBrKzs7n55ps555xzOOSQQxg9ejTt2rXjgw8+YNGiRSxatAiAm2++mf79+9O3b1/OP/989ttvP7744gsefPBB/vKXv9C5c2d69uzJUUcdxZVXXsnq1avZ8/+3d+9BWpX3Ace/v11jdC0qQkLEOhVNlBFn6tjMVoj1GmLVod4T6DD10hjRthrWcVDrNTYxgVmN0aaaCMaKVKM13hqwamMywdtg1DR4acZIcNRoVVIRxCy7v/5xzuL6uqwvCO9l3+9n5p33nOd5ds9vd5aH83ufyxkzhrvuuut960Q/zIgRIzjooIOYPXs2a9asYbfddmPJkiXcdtttH1hfPH36dBYsWMAll1zCk08+ySGHHEJvby8PPfQQe++997pHHgHsscceTJw4kVtuuYVRo0ZxxBFHbMRv9z3d3d1MnjyZfffdl1NPPZXM5Nprr2XNmjVcfvnlH+l7b2rjxo1j9uzZdHV10dnZybHHHsuoUaNYvnw5ixYtYq+99lr3bN9p06ZxzjnncPTRR3PmmWfS09PDvHnzGDNmDC+++OImjWvWrFncfPPNHHXUUeserXTrrbeyePFi5syZM+Tjkqq1IX9PkiRJan4mwzV23ReL98rnDG/9sfeeM1wrN954I+3t7UMme0ceeSQLFy5k0aJFTJkyZV0CfNlllzFnzhz6+vrYddddmT59+rqvmTBhAo899hgXXXQRN9xwAytXrmTs2LFMnjz5fVNN58+fz4wZM+ju7qajo4Np06Zx2mmnMWHChKp/hgULFtDV1cXcuXNZs2YNnZ2d3HfffZx11lnva9fW1sadd97J7NmzmT9/PgsXLmTbbbdln3324YADDvjA9z3xxBN5+OGHmTp16kY953eg/fffnwceeIALL7yQSy+9FIDOzk5uuukmJk2a9JG+9+Ywc+ZMdt99d7q7u7nssstYu3YtY8eOZb/99mPGjBnr2o0cOZI77riDrq4uZs2axU477URXVxcjRozgpJNO2qQxjR49msWLF3Puuedy3XXXsXLlSvbYYw/mzZu3Sa9V7d+TJEmSml9Us0nNcBURxcOG1/M76OkpstUNecxNtZ54qdg1+s3VxRrhafvUdgdpDe3666/n5JNP5tFHH6Wzs7Pe4agJbM7+QpIkSRunf6PVzPzA7q8mw9QnGVZjmzhxIm+99RZLly6tdyhqEvYXkiRJjWeoZNhp0lJp1apV3H333SxevJhHHnmEuXPn1jskSZIkSZuJI8M4MqzCsmXLGDduHNtttx0nnHACV1xxBW1tbriu6thfSJIkNR6nSa+HybCkTcX+QpIkqfEMlQw77CVJkiRJajkmw5K0CbTyLBtJkqRmZDI8hLa2Nnp7e+sdhqQm0NfX5xpzSZKkJuKd2xDa29vp6elxxEfSkDKTnp4e2tvb6x2KJEmSquQGWgw9vbGvr4/Vq1cTEbS3t9PW1rZuEbak1pWZ9PX10dvbS2bS0dHhyLAkSVKDcTfp9agmGe7Xf+Pb19e32eOS1Bza2tr8gEySJKmBmQyvx4Ykw5IkSZKk5uKjlSRJkiRJGqCpk+GI2DMiHoiI1RHxckR8LSLcwUaSJEmSNKQt6h3AxoqIkcD9wNPAkcBuQDdFgn9+HUOTJEmSJDW4pk2GgRnA1sAxmfkWcF9EbAtcHBGzyzJJkiRJkj6gmadJHwbcW5H03kyRIB9Qn5AkSZIkSc2gmZPh8cCzAwsyczmwuqyTJEmSJGlQzTxNeiTw+0HKV5R1VfMZoZIkSZLUWpp5ZBhgsAcEx3rK32sQ8ZWIWLJ5QpIkSZIkNbpmHhleAWw/SPl2DD5ivE5mfg/43uYIqhYiYklmfrbecUhqfPYXkqphXyGpGsOtr2jmkeFnqVgbHBE7A9tQsZZYkiRJkqSBmjkZXggcGhEjBpR9CXgH+Gl9QpIkSZIkNYNmToavAd4Fbo+Iz0fEV4CLgctb4BnDTTvFW1LN2V9IqoZ9haRqDKu+IjKH3GuqoUXEnsDVwESKdcLXARdnZm9dA5MkSZIkNbSmToYlSZIkSdoYzTxNWpIkSZKkjWIyLEmSJElqOSbDTSIiToyIHOQ1o96xSaqfiPh0RFwbEU9FRG9EPDhIm4iI8yLixYh4JyJ+FhF71yFcSXUQEcdHxF0R8VJEvB0Rj0fEtEHanRIRv46INWWbQ+oRr6T6iYjjIuKhiHij7Auei4jzI2LLAW2GzX2FyXDzOZhiw7D+1+31DUdSnU0ADgf+p3wN5hzgAuBbwBTgbeD+iPhUTSKUVG9dFP/uZwJ/BfwEWBAR/9DfICKmUjyp41+Bw4ClwD0RsVftw5VUR6Mo+ogvU/QF84B/BC4f0GbY3Fe4gVaTiIgTgeuBEZn5dp3DkdQgIqItM/vK49uA0Zl54ID6rYBXge7M/FpZtg2wDLg2M8+vedCSaioiRmfm6xVlC4CJmTmuPH8OWJyZJ5fnbcBTwFOZOb3WMUtqHBHxdeDvgJHAxxlG9xWODEtSE+tPhIcwCdgW+OGAr1kF3E3xia+kYa4yES49AXwSICJ2BXbn/f1EH3Ar9hOS4A2gf5r0sLqvMBluPs9HxNpy/v6p9Q5GUsMbD/QCv64of6ask9SaJgFPl8f9fcGzFW2eAXaIiE/ULCpJDSEi2iOiIyL2A84A/iWLKcXD6r5ii3oHoKq9QjE3/zGgHZgGXBMRHZl5RV0jk9TIRgJvZ2ZvRfkKoCMitszMP9QhLkl1Um6MdSRwclk0snz/fUXTFQPq/7cGoUlqHKsopkRDsZfA2eXxsLqvMBluEpl5L3DvgKKFEfFx4PyIuLKKqZKSWtdgm0PEEHWShqmI2AVYANyZmT+oqK7sD+wnpNY1CegAOoELgauB08u6YXNfYTLc3G4DvgjsAvymvqFIalArgBER0V7xKe72wOrM7KlTXJJqLCJ2ABYCy4GBm2L1jwBvD/zfgPLty/fKEWNJw1xm/qI8/HlEvA7cEBHdDLP7CtcMDw9N9QmMpJp6lmJpxacrysfzwfWBkoapiOgA7qHYBOeIcsObfv19QeV6v/HAm5npFGmptfUnxuMYZvcVJsPN7VjgdeC39Q5EUsN6CHgLOL6/oLwpnkIxQiRpmIuILSh21zSRWAAABNtJREFUhv4McFhmvjawPjN/Q/Gc8oH9RFt5bj8h6XPl+wsMs/sKp0k3iYj4d4rNs35J8WnMl8rXGa4XllpX+R/Q4eXpTsC2EXFcef7jzFwdEd8ELoiIFRSf2nZRfBh6Vc0DllQP36XoJ86k2B163wF1T2Tmu8DFwPyIWAYsBk6gSJ7/urahSqqniFgE3A8spdg1+nPAWcAtmfl82WbY3FdEsUO2Gl1EfINiJHhnigXqTwPfzswb6xqYpLoqN8N5YT3V4zJzWUQEcB5wGjAKWELxQdoTNQlSUl2VCe6frKd6XGYuK9udAsyiuNdYCpydmQ/UIkZJjSEiLgWOptiTaC3FvkTXA9f0rwceTvcVJsOSJEmSpJbjmmFJkiRJUssxGZYkSZIktRyTYUmSJElSyzEZliRJkiS1HJNhSZIkSVLLMRmWJEmSJLUck2FJkuokIrKK14E1iOPm8lpXDlL3q4i4ZsD5zhHxXxHxVkT8R0SMrmi/Z0S8ERFjNnfckiR9FCbDkiTVz8QBr4PLsn+qKP9FDeM5JSI++SFtrgLeAY4DRgCzK+qvAL6Vma9uhvgkSdpktqh3AJIktarMfKT/OCL+qDx8fmB5Df0S+GOgCzhniHaHAJMy878j4l1gfn9FREwBdgOmbM5AJUnaFBwZliSpCUTEZyPiwYhYXU5DvmHgFOWIGF9OdT6+nPb8dkT8LiLOrfISK4HvAKdHxMj1xBDAlhQjwwCry3Mi4mNAN3BWZv5hI39MSZJqxmRYkqQGFxE7Aj8B2oGpFKO3hwKLIqJylte3gdeBY4EbgG9ExN9WeanvlO9nDlaZmUkxbbs/YT4dWFJWnwEsz8w7q7yWJEl15TRpSZIa3yzgXeAvM3MVQES8APyUYkryjwa0fTwz/748vjcixgLnA3M/7CKZuSIivgucERHdmblykGYzgXvK95eBQyPiE8B5wIEb88NJklQPjgxLktT4OoEf9yfCAJn5M+B3wH4VbX9UcX47sEsVG2P1uxzYimLU9wPK9cw7AeOBXTLzV8DXgZvLdcRTI+L5iHg5Ii6o8pqSJNWcybAkSY1vR2Cw3ZlfBXaoKHttPec7VnOhzHwN+D7QFRFbr6fNu5n5XGb2RMSfAscAF0bEzuXXTgP+HDg1Ij5fzXUlSao1k2FJkhrfK8BgI7tjgDcryirb9Z+/sgHXmw1sD5xSRdsrgUsz8w1gEvBUZj6WmS8CdwAHbcB1JUmqGZNhSZIa36PA4RHR0V8QEX8BfAr4eUXboyvOjwF+W474ViUzXwJ+AJxNuVv0YCLiOIqE/J8HFHcMON4GiGqvK0lSLZkMS5LU+OZQrONdGBFTIuJvgFuAx4G7K9r+WURcFRFfiIhvAdMp1vRuqG9SJNufGawyIrYq45qZmWvL4oeBCRHx1YiYChwHPLgR15YkabMzGZYkqcFl5svAweXpDyken3Q/xe7Sayuaf5Uiib0dOBG4IDO/vxHXfAH4tyGadAFPZ+aiAV+zHPhyWXc10J2Z/7mh15YkqRaieGSgJElqZhExHngGmJyZ99c7HkmSGp0jw5IkSZKklmMyLEmSJElqOU6TliRJkiS1HEeGJUmSJEktx2RYkiRJktRyTIYlSZIkSS3HZFiSJEmS1HJMhiVJkiRJLcdkWJIkSZLUcv4f+EM7XJISxF0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "################################## Top n% Predictions ###########################\n",
    "topNValues = [5, 10, 20, 30]\n",
    "##############################################################################################################\n",
    "\n",
    "accuraciesHealthy, accuraciesPneumonia = [], []\n",
    "for topn in topNValues:\n",
    "    accuracyHealthy, accuracyPneumonia = calculateClasswiseTopNAccuracy(testLabels, bestAccPredictionProbabilities, topn)\n",
    "    accuraciesHealthy.append(accuracyHealthy)\n",
    "    accuraciesPneumonia.append(accuracyPneumonia)\n",
    "    \n",
    "    print(\"+ Accuracy for top %d percent predictions for healthy: %.2f, pneumonia: %.2f\" % (topn, accuracyHealthy, accuracyPneumonia))\n",
    "    \n",
    "# Plot results\n",
    "x = np.arange(len(accuraciesHealthy))\n",
    "plt.plot(x, accuraciesHealthy, linewidth = 3, color = '#e01111')\n",
    "scatterHealthy = plt.scatter(x, accuraciesHealthy, marker = 's', s = 100, color = '#e01111')\n",
    "plt.plot(x, accuraciesPneumonia, linewidth = 3, color = '#0072ff')\n",
    "scatterPneumonia = plt.scatter(x, accuraciesPneumonia, marker = 'o', s = 100, color = '#0072ff')\n",
    "plt.xticks(x, topNValues, fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.xlabel(\"Top N%\", fontsize = 15)\n",
    "plt.ylabel(\"Accuracy\", fontsize = 15)\n",
    "plt.legend([scatterHealthy, scatterPneumonia], [\"Accuracy for Healthy\", \"Accuracy for Pneumonia\"], fontsize = 17)\n",
    "plt.ylim(0, 110)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 256, 256, 8)       80        \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 256, 256, 8)       584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 128, 128, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 4,427,802\n",
      "Trainable params: 4,427,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
